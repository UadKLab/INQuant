from tqdm.auto import tqdm
from math import floor, ceil
import random
# From the module import functions, classes and variables
from . import *

class Calibration:
    def __init__(self, predictions_dict = dict()):
        """ Initializes the Calibration class with an INQuant instance.

        Parameters
        ----------
        predictions_dict : dict
            A dictionary containing dataframes of predictions for each mzML file, as also generated by load_predictions() in INQuant. 

        Attributes
        ----------
        sorted_predictions_dict : dict
            A dictionary to store sorted predictions.
        calibrated_predictions_dict : dict
            A dictionary to store calibrated predictions.
        unimod_dict : dict
            A dictionary to store Unimod IDs and their corresponding monoisotopic masses.
        ppm_tolerances : dict
            A dict to store maximum ppm tolerances for each mzML file, as recommended tolerance for quantification.
        
        Returns
        -------
        None
        
        """
        self.sorted_predictions_dict = predictions_dict  
        self.calibrated_predictions_dict = {}
        self.unimod_dict = {}
        self.ppm_tolerances = {}

    def load_mzml(self, mzml_path = str):
        """ Loads the mzML file and extracts spectra data.
        
        Parameters
        ----------
        mzML_path : str
            The path to the mzML file to be loaded.
        
        Attributes
        ----------
        exp : MSExperiment
            An object to store the loaded mzML data.
        spectra_data : dict
            A dictionary to store spectra data, including measured m/z, retention time, peaks, and charge.
            
        Returns
        -------
        None

        """
        self.exp = MSExperiment()
        print(f"Loading mzml: {mzml_path.split('/')[-1]}")
        MzMLFile().load(mzml_path, self.exp)
        max_spectra = self.exp.getNrSpectra() 

        # Save all needed information in a dict, because opening the experiment is time-consuming
        self.spectra_data = {i:{'meas_mz':self.exp.getSpectrum(i).getPrecursors()[0].getMZ() if self.exp.getSpectrum(i).getPrecursors() != [] else '',
                                'rt':self.exp.getSpectrum(i).getRT(),
                                'peaks':self.exp.getSpectrum(i).get_peaks(), 
                                'charge': self.exp.getSpectrum(i).getPrecursors()[0].getCharge() if self.exp.getSpectrum(i).getPrecursors() != [] else ''
                                } for i in range(max_spectra)}
    
    def weight(self, grid_point, return_adjustment = bool):
        """ Calculates the weights for the grid points based on the given grid point.
        
        Parameters
        ----------
        grid_point : list
            A list containing the grid point coordinates for a data point.
        return_adjustment : bool
            If True, returns the adjustment factor. 
            If False, returns the weightsn for each grid point.

        Returns
        -------
        list or float
            If return_adjustment is True, returns the adjustment factor.
            If return_adjustment is False, returns a list of weights for each grid point.
        
        
        """
        # Get the distance from the grid point to the floor values for rt and mz
        d_rt_f = grid_point[0] - floor(grid_point[0])
        d_mz_f = grid_point[1] - floor(grid_point[1])

        # Calculate the weights for each grid point as the are of the diagonal rectangle
        w_ff = (1-d_rt_f)*(1-d_mz_f)
        w_fc = (1-d_rt_f)*d_mz_f
        w_cf = d_rt_f*(1-d_mz_f)
        w_cc = d_rt_f*d_mz_f

        # If return_adjustment is True, calculate the adjustment factor using the weights and the deviation matrix
        # This is used to calibrate
        if return_adjustment: 
            mz_adjustment_factor = (self.dev_matrix[floor(grid_point[0])][floor(grid_point[1])]*w_ff +
                     self.dev_matrix[floor(grid_point[0])][ceil(grid_point[1])]*w_fc +
                     self.dev_matrix[ceil(grid_point[0])][floor(grid_point[1])]*w_cf +
                     self.dev_matrix[ceil(grid_point[0])][ceil(grid_point[1])]*w_cc)
            
            return mz_adjustment_factor
        
        else:
            # If return_adjustment is False, return the weights for each grid point
            # This is used to create the weights for the calibration matrix
            return [w_ff, w_fc, w_cf, w_cc]

    def calibration(self, mzML_id, train_size = 0.10, rt_grids = 50, mz_grids = 200, set_training_seed = None):   
        """ Calibrates the predictions based on the mzML file and the specified parameters. 

        Parameters
        ----------
        mzML_id : str
            The ID of the mzML file to be calibrated.
        train_size : float, optional
            The fraction of data to be used for training (default is 0.10).
        rt_grids : int, optional
            The number of bins for the retention time grid (default is 50).
        mz_grids : int, optional
            The number of bins for the mass-to-charge ratio grid (default is 200).
        set_training_seed : int or None, optional
            The seed for random number generation (default is None).

        Attributes
        ----------
        dev_matrix : dict
            A dictionary to store the deviation matrix for calibration.
        total_weight : dict
            A dictionary to store the total possible weight for each grid point.
        grid_zero : np.array
            An array to store the zero point of the grid.
        grid_basis : np.array
            An array to store the basis of the grid.        
        
        Returns
        -------
        None
       
        """
        # Check if the training seed is valid
        while True:
            if set_training_seed != None:
                try: 
                    random.seed(int(set_training_seed))
                    break
                except ValueError:
                    answ = input(f"Seed must be interger or None. \nProceed (Y/n)?")
                    if answ.lower() == "y":
                        set_training_seed = input(f"Please input seed-number or None")
                        if set_training_seed.lower() == "none":
                            set_training_seed = None
                    else:
                        return
            else:
                break
        
        # Check if the train size is valid
        if train_size > 1 or train_size < 0:
            while True:
                answ = input(f"Train size must be between 0 and 1. \nProceed (Y/n)?")
                if answ.lower() == "y":
                    train_size = input(f"Please input train size between 0 and 1")
                    if train_size <= 1 and train_size >= 0:
                        break


        def get_mass(sequence):

            mass = aa_mass['H2O'] + proton_da # H2O, because the AA weight are for bound AA, not free
            sequence_stripped = f"{re.sub(r'[^A-Z]', '', sequence)}".replace('I','L')

            for aa in sequence_stripped:
                mass += aa_mass[aa]
                    
            if '(' in sequence:
                # Find all modifications along with their starting index
                mod = [f"{m.start()}({m.group(1)})" for m in re.finditer(r"\((.*?)\)", sequence)]
                
                for m in mod: 
                    m = re.search(r"\((.*?)\)", m).group(1)
                    try:
                        mass += float(m)
                    except ValueError:
                        if m == 'ox':  
                            mass += 15.99491463
                        else:
                            print(f'Error: Could not convert modification mass to float: {m}')
            if '[' in sequence:
                # Find all modifications along with their starting index
                mod = [f"{m.start()}({m.group(1)})" for m in re.finditer(r"\[(.*?)\]", sequence)]
                
                for m in mod: 
                    m = re.search(r"\[(.*?)\]", m).group(1)
                    try:
                        mass += self.unimod_dict[m]
                    except KeyError:
                        # If the modification is not in the dictionary, try to get it from Unimod   
                        mass += get_monoisotopic_mass(m)
                        self.unimod_dict[m] = get_monoisotopic_mass(m)
                    except ValueError:
                        print(f'Error: Could not find unimod modification: {m}')
                    
            return mass


        filtered_df = self.sorted_predictions_dict[mzML_id]

        # Collect all the necessary information from the spectra data
        filtered_df['rt'] = [self.spectra_data[spec]['rt'] for spec in filtered_df['scan_number']]
        filtered_df['charge'] = [self.spectra_data[spec]['charge'] for spec in filtered_df['scan_number']]
        filtered_df['meas_mz'] = [self.spectra_data[spec]['meas_mz'] for spec in filtered_df['scan_number']]
        filtered_df['meas_mass'] = [self.spectra_data[spec]['charge']*self.spectra_data[spec]['meas_mz'] - (self.spectra_data[spec]['charge']-1)*proton_da for spec in filtered_df['scan_number']]
        
        # Calculate theoretical values
        filtered_df['theo_mass'] = [get_mass(sequence) for sequence in filtered_df['preds']]            
        filtered_df['theo_mz'] = (filtered_df['theo_mass']+proton_da*(filtered_df['charge']-1))/filtered_df['charge']
        
        # Calculate errors between theoretical and measured values
        filtered_df['mz_error'] = filtered_df['meas_mz'] - filtered_df['theo_mz']
        filtered_df['mass_error'] =  filtered_df['meas_mass'] - filtered_df['theo_mass']

        # Adjusted mass based on isotopes
        filtered_df['iso_adj_mass'] = filtered_df['meas_mass']-round(filtered_df['mass_error'])*neutron_da
        filtered_df['iso_adj_mz'] = (filtered_df['iso_adj_mass']+proton_da*(filtered_df['charge']-1))/filtered_df['charge']
        filtered_df['iso_adj_mz_error'] = filtered_df['iso_adj_mz'] - filtered_df['theo_mz']
        
        # Calculate the ppm error
        filtered_df['ppm'] = ((10**6)*filtered_df['iso_adj_mz_error'])/filtered_df['theo_mz']
        
        # Mark all predictions as not used for training
        filtered_df['train'] = False

        filtered_dict = filtered_df.set_index('scan_number').to_dict(orient='index')
        

        # Create tje deviation matrix and total weight matrix based on the number of grid
        self.dev_matrix = {}
        self.total_weight = {}

        for i in range(rt_grids+1):
            self.dev_matrix[i] = {}
            self.total_weight[i] = {}
            for j in range(mz_grids+1):
                self.dev_matrix[i][j] = 0
                self.total_weight[i][j] = 0

        # Get the minimum and maximum values for the grid, to make sure the grid is big enough to cover all data points
        min_mz = min([min(self.spectra_data[i]['peaks'][0]) for i in self.spectra_data.keys()] + filtered_df['iso_adj_mz'].tolist())
        self.grid_zero = np.array([floor(self.spectra_data[0]['rt']), floor(min_mz)])
        
        max_mz = max([max(self.spectra_data[i]['peaks'][0]) for i in self.spectra_data.keys()] + filtered_df['iso_adj_mz'].tolist())
        grid_max = np.array([ceil(self.spectra_data[len(self.spectra_data)-1]['rt']), ceil(max_mz)])
        
        grid_size = np.array([rt_grids, mz_grids])
        
        # Calculate a new grid basis based on the range of rt and m/z values, to ensure that each grid cell has the same size. 
        self.grid_basis = (grid_max - self.grid_zero)/grid_size
        
        # Take a random sample of the data points for training
        train_filtered_dict = {key: filtered_dict[key] for key in random.sample(list(filtered_dict.keys()), int(train_size * len(filtered_dict)))}
            
        for i,(key, prediction) in tqdm(enumerate(train_filtered_dict.items()),total=len(train_filtered_dict),desc=f'Creating calibration matrix for {mzML_id}'):
            # Mark the selected predictions as used for training
            filtered_dict[key]['train'] = True

            # Calculate the grid point for the data point
            data_point = np.array([prediction['rt'], prediction['iso_adj_mz']])
            grid_point = (data_point - self.grid_zero) / self.grid_basis

            # Calculate the weights for the grid point
            weights = self.weight(grid_point, return_adjustment=False)

            # Define four points in matrix around grid point
            indices = [
                (floor(grid_point[0]), floor(grid_point[1])),
                (floor(grid_point[0]), ceil(grid_point[1])),
                (ceil(grid_point[0]), floor(grid_point[1])),
                (ceil(grid_point[0]), ceil(grid_point[1])),
            ]

            # Update dev_matrix and total_weight for all indices, using the weights and the relative error
            rel_error = prediction['ppm']
            for i, (x, y) in enumerate(indices):
                self.dev_matrix[x][y] += rel_error * weights[i]
                self.total_weight[x][y] += weights[i]

        # Normalize the dev_matrix by dividing by the total weight for each grid point
        self.dev_matrix = {key1: {key2: (value2/(self.total_weight[key1][key2]) if value2 != 0 else 0) for key2, value2 in value.items()} for key1, value in self.dev_matrix.items()}

        calibrated_ppm_error = []
        # Calibrate the predictions using the weights and the deviation matrix
        for i,(spec_number, prediction) in tqdm(enumerate(filtered_dict.items()),total=len(filtered_dict),desc=f'Calibrating {mzML_id}'):
            
            # Calculate the grid point for the data point
            data_point = np.array([prediction['rt'], prediction['iso_adj_mz']])
            grid_point = (data_point - self.grid_zero)/self.grid_basis

            # Calculate the adjustment factor for the data point
            adjustment = self.weight(grid_point, return_adjustment = True)

            # Calculate the calibrated m/z value using the adjustment factor
            prediction['calibrated_mz'] = data_point[1]/(1+adjustment*10**(-6))
            prediction['calibrated_mz_error'] = prediction['calibrated_mz'] - prediction['theo_mz']
            
            # Save the calibrated predictions in a dictionary, with both the original and calibrated values
            index = len(self.calibrated_predictions_dict)
            self.calibrated_predictions_dict[index] = {'scan_number': spec_number+1,
                                            'file': prediction['file'],
                                            'preds': prediction['preds'],
                                            'log_probs': prediction['log_probs'],
                                            'rt': prediction['rt'],
                                            'charge': prediction['charge'],
                                            'meas_mz': prediction['meas_mz'],
                                            'iso_adj_mz': prediction['iso_adj_mz'],
                                            'theo_mz': prediction['theo_mz'],
                                            'calibrated_mz': prediction['calibrated_mz'],
                                            'meas_mz_error': prediction['mz_error'],
                                            'iso_adj_mz_error': prediction['iso_adj_mz_error'],
                                            'calibrated_mz_error': prediction['calibrated_mz_error'], 
                                            'train': prediction['train']}
            
            calibrated_ppm_error.append(10**6*prediction['calibrated_mz_error']/prediction['theo_mz'])
        
        # Save the maximum ppm error
        recommended_ppm_tolerance = max(calibrated_ppm_error)
        self.ppm_tolerances[mzML_id] = recommended_ppm_tolerance
        
    def get_ppm_tolerance(self):
        """ Returns the maximum ppm tolerance from the list of ppm tolerances. This is the recommended m/z tolerance for calculating quantification in INQuant.

        Returns
        -------
        max_ppm_tolerance : float
            The maximum ppm tolerance from all the predictions.

        """
        if len(self.ppm_tolerances) == 0:
            print("No ppm tolerances found. Please run the calibration method first.")
            return None

        return max(self.ppm_tolerances.values())
    
    def write_calibrated_mzml_file(self, file_path, mzml_name):
        """ Writes the calibrated predictions to a CSV file.
        
        Parameters
        ----------
        file_path : str
            The path where the calibrated predictions CSV file will be saved.

        mzml_name : str
            The ID of the mzML file to be saved.
        
        Returns
        -------
        new_predictions : str
            The path of the new calibrated predictions CSV file.
        
        new_mzml : str
            The path of the new mzML file with calibrated spectra.

        """

        if self.exp.size() > 0:
            # List to store the modified spectra
            spectra = []
            # Modify each spectrum by calibrating the m/z values
            for i,_ in tqdm(enumerate(self.exp),total=self.exp.size(),desc=f'Creating calibrated mzML file: {mzml_name}'):
                spectrum = self.exp.getSpectrum(i)
                rt = spectrum.getRT()
                calibrated_mz = []
                
                # Iterate over the m/z values in the spectrum and apply the calibration
                for mz in spectrum.get_peaks()[0]:
                    data_point = np.array([rt, mz])
                    grid_point = (data_point - self.grid_zero)/self.grid_basis
                    error = self.weight(grid_point, return_adjustment = True)

                    calibrated_mz.append((mz/(1-error*10**(-6))))

                precursor = spectrum.getPrecursors()[0] if spectrum.getPrecursors() != [] else None
                
                # If the spectrum has a precursor, calibrate its m/z value as well
                if precursor is not None: 
                    precursor_mz = precursor.getMZ() 
                    data_point = np.array([rt, precursor_mz])
                    grid_point = (data_point - self.grid_zero)/self.grid_basis

                    error = self.weight(grid_point, return_adjustment = True)

                    calibrated_precursor_mz = (precursor_mz/(1-error*10**(-6)))
                    
                    precursor.setMZ(calibrated_precursor_mz)
                    spectrum.setPrecursors([precursor])

                # Set the calibrated m/z values in the spectrum
                spectrum.set_peaks((np.array(calibrated_mz), spectrum.get_peaks()[1]))
                spectra.append(spectrum)
            
            # Set the modified spectra back to the experiment
            self.exp.setSpectra(spectra)
                    
        # Save the modified data to a new mzML file
        new_mzml = f"{file_path}{mzml_name}_calibrated.mzML"
        MzMLFile().store(new_mzml, self.exp)

        self.exp = MSExperiment()

        return new_mzml
    
    def write_calibrated_predictions_file(self, file_path, predictions_name = str):
        """ Writes the calibrated predictions to a CSV file.

        Parameters
        ----------
        file_path : str
            The path where the calibrated predictions CSV file will be saved.
        
        predictions_name : str
            The name of the predictions file to be saved.
        
        Returns
        -------
        new_predictions : str
            The path of the new calibrated predictions CSV file.

        """
        
        new_predictions = f"{file_path}{predictions_name}_calibrated.csv"
        pd.DataFrame.from_dict(self.calibrated_predictions_dict, orient='index').to_csv(new_predictions, index=False)
        
        print(f"Calibrated predictions saved to {new_predictions}")

        return new_predictions